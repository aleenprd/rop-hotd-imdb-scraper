{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Methods related to scraping.\"\"\"\n",
    "\n",
    "\n",
    "# IMPORTING PACKAGES\n",
    "# -------------------------------------- #\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re as regex\n",
    "from typing import Dict, List\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "import traceback\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_soup(url: str, header: str) -> BeautifulSoup:\n",
    "    \"\"\"\n",
    "    Return an HTML body from an URL.\n",
    "\n",
    "    Obs: Soup is not enoug hfor this site.\n",
    "    We need to interact with the JavaScript,\n",
    "    so we will use Selenium with ChromeDriver.\n",
    "    \"\"\"\n",
    "    r = requests.get(url, headers=header)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "    return soup\n",
    "\n",
    "def make_soup_with_selenium(\n",
    "    url: str,\n",
    "    driver_service\n",
    ") -> BeautifulSoup:\n",
    "    \"\"\"\n",
    "    Return an HTML body from an URL.\n",
    "\n",
    "    Obs: Soup is not enoug hfor this site.\n",
    "    We need to interact with the JavaScript,\n",
    "    so we will use Selenium with ChromeDriver.\n",
    "    \"\"\"\n",
    "    chromedriver = webdriver.Chrome(service=driver_service)\n",
    "    chromedriver.maximize_window()\n",
    "    chromedriver.get(url)\n",
    "    sleep(5)\n",
    "\n",
    "    page_source = chromedriver.page_source\n",
    "    soup = BeautifulSoup(page_source, 'lxml')\n",
    "    chromedriver.quit()\n",
    "    return soup\n",
    "\n",
    "def get_episodes_links(link, driver_service):\n",
    "    soup = make_soup_with_selenium(link, driver_service)\n",
    "    website = \"https://www.imdb.com\"\n",
    "    \n",
    "    links = []\n",
    "    for link in soup.find_all('a', href=True):\n",
    "        href = link[\"href\"]\n",
    "        if bool(regex.search('=ttep_ep\\d$', href)):\n",
    "            links.append(href) \n",
    "            \n",
    "    links = list(set(links))\n",
    "    links.sort()\n",
    "    links = [f\"{website}{l}\" for l in links]\n",
    "    \n",
    "    return links\n",
    "\n",
    "\n",
    "def get_ratings_page(episode_page, suffix=\"/ratings/?ref_=tt_ov_rt\"):\n",
    "    return (\"/\").join(episode_page.split(\"/\")[:-1]) + suffix \n",
    "\n",
    "def get_reviews_page(episode_page, suffix=\"/reviews?ref_=tt_urv\"):\n",
    "    return (\"/\").join(episode_page.split(\"/\")[:-1]) + suffix \n",
    "\n",
    "def scroll_reviews_and_cook_soup(link: str, driver_service):\n",
    "    chromedriver = webdriver.Chrome(service=driver_service)\n",
    "    chromedriver.maximize_window()\n",
    "    chromedriver.get(link)\n",
    "    sleep(10)\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            loadMoreButton = chromedriver.find_element(By.ID, \"load-more-trigger\")\n",
    "            time.sleep(2)\n",
    "            loadMoreButton.click()\n",
    "            sleep(3)\n",
    "        except Exception as e:\n",
    "            print(\"Exception :\", e)\n",
    "            break\n",
    "    # Get page source code\n",
    "    page_source = chromedriver.page_source\n",
    "    reviews_soup = BeautifulSoup(page_source, 'lxml')\n",
    "    chromedriver.quit()\n",
    "    return reviews_soup\n",
    "\n",
    "def fetch_el_if_available(soup, element_type: str, class_type: str):\n",
    "    element = soup.find(element_type, class_type)\n",
    "    if element is not None:\n",
    "        element = element.text\n",
    "    return element\n",
    "\n",
    "def scrape_reviews_page(reviews_soup):\n",
    "    review_ratings = []\n",
    "    user_names = []\n",
    "    review_dates = [] \n",
    "    review_titles = []\n",
    "    review_texts = []\n",
    "    num_helpful_reactions = []\n",
    "    num_total_reactions = []\n",
    "    \n",
    "    review_boxes = reviews_soup.find_all('div', {\"class\": \"lister-item\"})\n",
    "    \n",
    "    for review in review_boxes:\n",
    "        # Rating of review\n",
    "        review_rating = fetch_el_if_available(review, \"div\", \"ipl-ratings-bar\")\n",
    "        if review_rating is not None:\n",
    "            review_rating = review_rating.replace(\"\\n\", \"\").split(\"/\")[0]\n",
    "        review_ratings.append(review_rating)\n",
    "\n",
    "        # User name plus date of review\n",
    "        user_name_and_date = fetch_el_if_available(review, \"div\", \"display-name-date\")\n",
    "        if user_name_and_date is not None:\n",
    "            user_name_and_date = user_name_and_date.replace(\"\\n\", \"\").split(\" \")\n",
    "            user_names.append(user_name_and_date[0])\n",
    "            review_dates.append(user_name_and_date[1] + \" \" + user_name_and_date[2])\n",
    "        else:\n",
    "            user_names.append(None)\n",
    "            review_dates.append(None)\n",
    "        \n",
    "        # Title of review\n",
    "        review_title = fetch_el_if_available(review, \"a\", \"title\")\n",
    "        if review_title is not None:\n",
    "            review_title = review_title.replace(\"\\n\", \"\")\n",
    "        review_titles.append(review_title)\n",
    "        \n",
    "        # Text of review\n",
    "        review_text = fetch_el_if_available(review, \"div\", \"text\")\n",
    "        if review_title is not None:\n",
    "            review_text = review_text.replace(\"\\n\", \"\")\n",
    "        review_texts.append(review_text)\n",
    "        \n",
    "        # Review Reactions\n",
    "        reactions = fetch_el_if_available(review, \"div\", \"actions\")\n",
    "        if reactions is not None:\n",
    "            reactions = reactions.replace(\"\\n\", \"\").strip().split(\" \")\n",
    "            num_helpful_reactions.append(reactions[0])\n",
    "            num_total_reactions.append(reactions[3])\n",
    "        else:\n",
    "            num_helpful_reactions.append(None)\n",
    "            num_total_reactions.append(None)\n",
    "    \n",
    "    df_out = pd.DataFrame()\n",
    "    df_out[\"review_rating\"] = review_ratings\n",
    "    df_out[\"user_name\"] = user_names\n",
    "    df_out[\"review_date\"] = review_dates\n",
    "    df_out[\"review_title\"] = review_titles\n",
    "    df_out[\"review_text\"] = review_texts\n",
    "    df_out[\"num_helpful_reactions\"] = num_helpful_reactions\n",
    "    df_out[\"num_total_reactions\"] = num_total_reactions\n",
    "\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from urllib.request import urlopen\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re as regex\n",
    "from typing import Dict, List\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "import traceback\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "season_link = \"https://www.imdb.com/title/tt7631058/episodes?ref_=tt_eps_sm\"\n",
    "show_link = \"https://www.imdb.com/title/tt7631058/?ref_=tt_urv\"\n",
    "output_path = \"rop_s1.csv\"\n",
    "driver_service = Service(ChromeDriverManager().install())\n",
    "episodes_links = get_episodes_links(link=season_link, driver_service=driver_service)\n",
    "print(episodes_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.imdb.com/title/tt10582302/?ref_=ttep_ep2', 'https://www.imdb.com/title/tt11609034/?ref_=ttep_ep3', 'https://www.imdb.com/title/tt11609038/?ref_=ttep_ep4', 'https://www.imdb.com/title/tt11609040/?ref_=ttep_ep5', 'https://www.imdb.com/title/tt11609042/?ref_=ttep_ep6', 'https://www.imdb.com/title/tt11609046/?ref_=ttep_ep7', 'https://www.imdb.com/title/tt11609048/?ref_=ttep_ep8', 'https://www.imdb.com/title/tt9788618/?ref_=ttep_ep1']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"rop_s1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4134\n",
       "1     248\n",
       "6     127\n",
       "8     120\n",
       "3     116\n",
       "2      84\n",
       "5      76\n",
       "4      61\n",
       "7      54\n",
       "Name: episode_number, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.episode_number.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_rating</th>\n",
       "      <th>user_name</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_text</th>\n",
       "      <th>num_helpful_reactions</th>\n",
       "      <th>num_total_reactions</th>\n",
       "      <th>episode_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>Dannyboi942</td>\n",
       "      <td>2 September 2022</td>\n",
       "      <td>Better than the first episode, but still miss...</td>\n",
       "      <td>Adrift is a better episode than the choppy fir...</td>\n",
       "      <td>110</td>\n",
       "      <td>195</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>TheOne7462</td>\n",
       "      <td>2 September 2022</td>\n",
       "      <td>Hopeful</td>\n",
       "      <td>First two episodes are good. On a technical as...</td>\n",
       "      <td>175</td>\n",
       "      <td>326</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>johndavidson-18</td>\n",
       "      <td>8 September 2022</td>\n",
       "      <td>Watchable, tolkien adjacent fantasy</td>\n",
       "      <td>This second episode of the series confirms wit...</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>vaderis3</td>\n",
       "      <td>3 September 2022</td>\n",
       "      <td>Weak tea</td>\n",
       "      <td>Neither better nor worse than the first episod...</td>\n",
       "      <td>22</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>quiqueperezsoler3</td>\n",
       "      <td>3 September 2022</td>\n",
       "      <td>An in-depth episode review. Summary: The plot...</td>\n",
       "      <td>The arrival of a being from the sky builds up ...</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5015</th>\n",
       "      <td>5.0</td>\n",
       "      <td>dmitryreus-803212</td>\n",
       "      <td>2 September 2022</td>\n",
       "      <td>NOT as bad as reviews say, but nothing specta...</td>\n",
       "      <td>If you put it into comparison with the origina...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5016</th>\n",
       "      <td>4.0</td>\n",
       "      <td>arne-299893</td>\n",
       "      <td>3 September 2022</td>\n",
       "      <td>Boring</td>\n",
       "      <td>Seems pretty standard stuff to me. The social ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5017</th>\n",
       "      <td>6.0</td>\n",
       "      <td>mintyrannosaurus2</td>\n",
       "      <td>2 September 2022</td>\n",
       "      <td>Not the worst but could've been better</td>\n",
       "      <td>I would give it a 6.5 if i can to be honest. T...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5018</th>\n",
       "      <td>5.0</td>\n",
       "      <td>victorevanbullard3</td>\n",
       "      <td>3 September 2022</td>\n",
       "      <td>Well done, but too many liberties taken.</td>\n",
       "      <td>While I concede that this is a well made show,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5019</th>\n",
       "      <td>6.0</td>\n",
       "      <td>riccardoeste3</td>\n",
       "      <td>3 September 2022</td>\n",
       "      <td>Great visuals, poor characters and dialogue</td>\n",
       "      <td>The CGI and cinematography are both really goo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5020 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      review_rating           user_name       review_date  \\\n",
       "0               6.0         Dannyboi942  2 September 2022   \n",
       "1               8.0          TheOne7462  2 September 2022   \n",
       "2               6.0     johndavidson-18  8 September 2022   \n",
       "3               3.0            vaderis3  3 September 2022   \n",
       "4               6.0   quiqueperezsoler3  3 September 2022   \n",
       "...             ...                 ...               ...   \n",
       "5015            5.0   dmitryreus-803212  2 September 2022   \n",
       "5016            4.0         arne-299893  3 September 2022   \n",
       "5017            6.0   mintyrannosaurus2  2 September 2022   \n",
       "5018            5.0  victorevanbullard3  3 September 2022   \n",
       "5019            6.0       riccardoeste3  3 September 2022   \n",
       "\n",
       "                                           review_title  \\\n",
       "0      Better than the first episode, but still miss...   \n",
       "1                                               Hopeful   \n",
       "2                   Watchable, tolkien adjacent fantasy   \n",
       "3                                              Weak tea   \n",
       "4      An in-depth episode review. Summary: The plot...   \n",
       "...                                                 ...   \n",
       "5015   NOT as bad as reviews say, but nothing specta...   \n",
       "5016                                             Boring   \n",
       "5017             Not the worst but could've been better   \n",
       "5018           Well done, but too many liberties taken.   \n",
       "5019        Great visuals, poor characters and dialogue   \n",
       "\n",
       "                                            review_text num_helpful_reactions  \\\n",
       "0     Adrift is a better episode than the choppy fir...                   110   \n",
       "1     First two episodes are good. On a technical as...                   175   \n",
       "2     This second episode of the series confirms wit...                    13   \n",
       "3     Neither better nor worse than the first episod...                    22   \n",
       "4     The arrival of a being from the sky builds up ...                     7   \n",
       "...                                                 ...                   ...   \n",
       "5015  If you put it into comparison with the origina...                     0   \n",
       "5016  Seems pretty standard stuff to me. The social ...                     0   \n",
       "5017  I would give it a 6.5 if i can to be honest. T...                     0   \n",
       "5018  While I concede that this is a well made show,...                     0   \n",
       "5019  The CGI and cinematography are both really goo...                     0   \n",
       "\n",
       "     num_total_reactions  episode_number  \n",
       "0                    195               2  \n",
       "1                    326               2  \n",
       "2                     18               2  \n",
       "3                     41               2  \n",
       "4                     11               2  \n",
       "...                  ...             ...  \n",
       "5015                   0               0  \n",
       "5016                   0               0  \n",
       "5017                   0               0  \n",
       "5018                   0               0  \n",
       "5019                   0               0  \n",
       "\n",
       "[5020 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"hotd_s1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2814"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Jun 22 2022, 20:18:18) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
